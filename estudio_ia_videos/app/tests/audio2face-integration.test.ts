/**
 * üß™ Testes de Integra√ß√£o Audio2Face
 * FASE 2: Sprint 1 - Valida√ß√£o de precis√£o de lip-sync ‚â•95%
 */

import { audio2FaceService } from '@/lib/services/audio2face-service'
import { avatar3DPipeline } from '@/lib/avatar-3d-pipeline'
import { supabaseClient } from '@/lib/supabase'

// Mock Supabase Client
jest.mock('@/lib/supabase', () => ({
  supabaseClient: {
    from: jest.fn().mockReturnThis(),
    select: jest.fn().mockReturnThis(),
    eq: jest.fn().mockReturnThis(),
    limit: jest.fn().mockReturnThis(),
    single: jest.fn().mockResolvedValue({
      data: { id: 'avatar-123', name: 'Test Avatar' },
      error: null
    })
  }
}));

// Mock Avatar 3D Pipeline
jest.mock('@/lib/avatar-3d-pipeline', () => ({
  avatar3DPipeline: {
    renderHyperRealisticAvatar: jest.fn().mockResolvedValue({
      jobId: 'job-123',
      status: 'processing',
      audio2FaceEnabled: true
    }),
    getRenderJobStatus: jest.fn().mockResolvedValue({
      status: 'completed',
      lipSyncAccuracy: 98,
      outputVideo: 'http://example.com/video.mp4'
    }),
    generateHyperRealisticLipSync: jest.fn().mockResolvedValue({
      success: true,
      audio2FaceEnabled: false,
      accuracy: 85
    })
  }
}));

describe('Audio2Face Integration Tests', () => {
  beforeAll(async () => {
    // Inicializar servi√ßos para teste
    console.log('üß™ Inicializando testes Audio2Face...')
  })

  afterAll(async () => {
    // Limpeza ap√≥s testes
    console.log('üß™ Finalizando testes Audio2Face...')
  })

  describe('Audio2Face Service Health Check', () => {
    test('deve verificar se o servi√ßo Audio2Face est√° dispon√≠vel', async () => {
      const healthCheck = await audio2FaceService.checkHealth()
      
      expect(healthCheck.isHealthy).toBe(true)
      expect(healthCheck.version).toBeDefined()
      expect(healthCheck.responseTime).toBeLessThan(5000) // 5 segundos
      
      console.log('‚úÖ Audio2Face Health Check:', healthCheck)
    }, 10000)

    test('deve listar inst√¢ncias dispon√≠veis', async () => {
      const instances = await audio2FaceService.listInstances()
      
      expect(Array.isArray(instances)).toBe(true)
      expect(instances.length).toBeGreaterThan(0)
      
      console.log('‚úÖ Audio2Face Instances:', instances)
    })
  })

  describe('Lip-Sync Accuracy Tests', () => {
    const testCases = [
      {
        name: 'Texto curto em portugu√™s',
        text: 'Ol√°, como voc√™ est√° hoje?',
        language: 'pt-BR',
        expectedMinAccuracy: 95
      },
      {
        name: 'Texto m√©dio em portugu√™s',
        text: 'Este √© um teste de sincroniza√ß√£o labial para verificar a precis√£o do sistema Audio2Face com texto de tamanho m√©dio.',
        language: 'pt-BR',
        expectedMinAccuracy: 95
      },
      {
        name: 'Texto longo em portugu√™s',
        text: 'A tecnologia de sincroniza√ß√£o labial baseada em intelig√™ncia artificial representa um avan√ßo significativo na cria√ß√£o de avatares hiper-realistas. O sistema Audio2Face da NVIDIA utiliza redes neurais profundas para analisar caracter√≠sticas ac√∫sticas do √°udio e gerar movimentos faciais precisos em tempo real.',
        language: 'pt-BR',
        expectedMinAccuracy: 95
      }
    ]

    testCases.forEach((testCase) => {
      test(`deve atingir precis√£o ‚â•${testCase.expectedMinAccuracy}% para: ${testCase.name}`, async () => {
        // Criar sess√£o Audio2Face
        const sessionId = await audio2FaceService.createSession({
          instanceName: 'test-instance',
          avatarPath: '/test/avatar.usd'
        })

        expect(sessionId).toBeDefined()

        try {
          // Gerar √°udio sint√©tico para teste
          const audioBuffer = await generateTestAudio(testCase.text, testCase.language)
          
          // Processar com Audio2Face
          const result = await audio2FaceService.processAudio(sessionId, audioBuffer, {
            outputFormat: 'arkit',
            frameRate: 60,
            quality: 'high'
          })

          // Validar resultado
          if (!result.success) {
            throw new Error(`Process failed: ${result.error}`)
          }
          
          expect(result.success).toBe(true)
          expect(result.lipSyncData).toBeDefined()
          expect(result.accuracy).toBeGreaterThanOrEqual(testCase.expectedMinAccuracy)
          
          console.log(`‚úÖ Lip-sync accuracy for "${testCase.name}": ${result.accuracy}%`)
          
          // Validar estrutura dos dados
          expect(result.lipSyncData.length).toBeGreaterThan(0)
          expect(result.metadata.frameRate).toBe(60)
          expect(result.metadata.totalFrames).toBeGreaterThan(0)

        } finally {
          // Limpar sess√£o
          await audio2FaceService.destroySession(sessionId)
        }
      }, 30000) // 30 segundos timeout
    })
  })

  describe('Pipeline Integration Tests', () => {
    test('deve integrar Audio2Face com pipeline de renderiza√ß√£o', async () => {
      // Buscar avatar de teste
      const { data: testAvatar } = await supabaseClient
        .from('avatar_models' as any)
        .select('*')
        .eq('is_active', true)
        .eq('audio2face_compatible', true)
        .limit(1)
        .single()

      expect(testAvatar).toBeDefined()
      if (!testAvatar) throw new Error('Test avatar not found')

      // Executar renderiza√ß√£o com Audio2Face
      const renderResult = await avatar3DPipeline.renderHyperRealisticAvatar(
        'test-user',
        'Este √© um teste de integra√ß√£o completa do pipeline.',
        undefined, // voiceProfileId
        {
          avatarId: (testAvatar as any).id,
          quality: 'high',
          resolution: '4K',
          audio2FaceEnabled: true,
          realTimeLipSync: true,
          rayTracing: false // Desabilitar para teste mais r√°pido
        }
      )

      expect(renderResult.jobId).toBeDefined()
      expect(renderResult.status).toBe('processing')
      expect(renderResult.audio2FaceEnabled).toBe(true)

      console.log('‚úÖ Pipeline integration test started:', renderResult.jobId!)

      // Aguardar processamento (ou simular)
      let attempts = 0
      let job: any = renderResult
      
      while (job.status === 'processing' && attempts < 10) {
        await new Promise(resolve => setTimeout(resolve, 2000)) // 2 segundos
        if (renderResult.jobId) {
            job = await avatar3DPipeline.getRenderJobStatus(renderResult.jobId)
        }
        attempts++
      }

      // Validar resultado final
      if (job.status === 'completed') {
        expect(job.lipSyncAccuracy).toBeGreaterThanOrEqual(95)
        expect(job.outputVideo).toBeDefined()
        console.log(`‚úÖ Pipeline completed with ${job.lipSyncAccuracy}% accuracy`)
      } else {
        console.log(`‚ö†Ô∏è Pipeline test timeout after ${attempts} attempts, status: ${job.status}`)
      }
    }, 60000) // 60 segundos timeout
  })

  describe('Performance Tests', () => {
    test('deve processar lip-sync em tempo aceit√°vel', async () => {
      const startTime = Date.now()
      
      const sessionId = await audio2FaceService.createSession({
        instanceName: 'performance-test',
        avatarPath: '/test/avatar.usd'
      })

      const audioBuffer = await generateTestAudio('Teste de performance', 'pt-BR')
      
      const result = await audio2FaceService.processAudio(sessionId, audioBuffer, {
        outputFormat: 'arkit',
        frameRate: 30, // Menor frame rate para teste de performance
        quality: 'medium'
      })

      const processingTime = Date.now() - startTime

      if (!result.success) {
        throw new Error(`Process failed: ${result.error}`)
      }

      expect(result.success).toBe(true)
      expect(processingTime).toBeLessThan(15000) // 15 segundos m√°ximo
      
      console.log(`‚úÖ Performance test: ${processingTime}ms for ${result.metadata.audioLength}s audio`)

      await audio2FaceService.destroySession(sessionId)
    }, 20000)
  })

  describe('Error Handling Tests', () => {
    test('deve lidar com √°udio inv√°lido graciosamente', async () => {
      const sessionId = await audio2FaceService.createSession({
        instanceName: 'error-test',
        avatarPath: '/test/avatar.usd'
      })

      try {
        // Tentar processar √°udio inv√°lido
        const invalidAudio = Buffer.alloc(100) // Buffer vazio
        
        const result = await audio2FaceService.processAudio(sessionId, invalidAudio, {
          outputFormat: 'arkit',
          frameRate: 60,
          quality: 'high'
        })

        if (result.success) {
          throw new Error('Expected failure but got success')
        }

        expect(result.success).toBe(false)
        expect(result.error).toBeDefined()
        
        console.log('‚úÖ Error handling test passed:', result.error)
      } finally {
        await audio2FaceService.destroySession(sessionId)
      }
    })

    test('deve usar fallback quando Audio2Face n√£o est√° dispon√≠vel', async () => {
      // Simular Audio2Face indispon√≠vel
      const originalCheckHealth = audio2FaceService.checkHealth
      audio2FaceService.checkHealth = jest.fn().mockResolvedValue({
        isHealthy: false,
        error: 'Service unavailable'
      })

      try {
        const result = await avatar3DPipeline.generateHyperRealisticLipSync(
          'test-avatar',
          '/test/audio.wav',
          'Teste de fallback',
          { language: 'pt-BR', quality: 'high' }
        )

        expect(result.success).toBe(true)
        expect(result.audio2FaceEnabled).toBe(false)
        expect(result.accuracy).toBeGreaterThan(0) // Fallback deve ter alguma precis√£o
        
        console.log('‚úÖ Fallback test passed with accuracy:', result.accuracy)
      } finally {
        // Restaurar m√©todo original
        audio2FaceService.checkHealth = originalCheckHealth
      }
    })
  })
})

/**
 * Fun√ß√£o auxiliar para gerar √°udio de teste
 */
async function generateTestAudio(text: string, language: string): Promise<Buffer> {
  // Em um ambiente real, isso usaria TTS para gerar √°udio
  // Para testes, retornamos um buffer simulado
  const audioLength = text.length * 50 // ~50ms por caractere
  const sampleRate = 44100
  const samples = Math.floor(audioLength * sampleRate / 1000)
  
  // Gerar √°udio sint√©tico simples (onda senoidal)
  const buffer = Buffer.alloc(samples * 2) // 16-bit audio
  
  for (let i = 0; i < samples; i++) {
    const frequency = 440 + Math.sin(i / 1000) * 100 // Varia√ß√£o de frequ√™ncia
    const amplitude = Math.sin(2 * Math.PI * frequency * i / sampleRate) * 32767
    buffer.writeInt16LE(amplitude, i * 2)
  }
  
  return buffer
}

/**
 * Configura√ß√£o de timeout global para testes
 */
jest.setTimeout(120000) // 2 minutos para testes completos